{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::023375022819:role/service-role/AmazonSageMaker-ExecutionRole-20181029T121824\n",
      "qanv-aws-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role) # This is the role that SageMaker would use to leverage AWS resources (S3, CloudWatch) on your behalf\n",
    "\n",
    "bucket = 'qanv-aws-1' #sess.default_bucket() # Replace with your own bucket name if needed\n",
    "print(bucket)\n",
    "#prefix = 'blazingtext/supervised' #Replace with the prefix under which you want to store the data if needed\n",
    "prefix = 'nlp/supervised' #Replace with the prefix under which you want to store the data if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-03-13 00:46:13--  https://s3.amazonaws.com/fast-ai-nlp/amazon_review_polarity_csv.tgz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.233.13\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.233.13|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 688339454 (656M) [application/x-tar]\n",
      "Saving to: ‘amazon_review_polarity_csv.tgz.1’\n",
      "\n",
      "amazon_review_polar 100%[===================>] 656.45M  48.1MB/s    in 13s     \n",
      "\n",
      "2019-03-13 00:46:26 (49.7 MB/s) - ‘amazon_review_polarity_csv.tgz.1’ saved [688339454/688339454]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/fast-ai-nlp/amazon_review_polarity_csv.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_review_polarity_csv/\n",
      "amazon_review_polarity_csv/train.csv\n",
      "amazon_review_polarity_csv/readme.txt\n",
      "amazon_review_polarity_csv/test.csv\n"
     ]
    }
   ],
   "source": [
    " \n",
    "!tar -xvzf amazon_review_polarity_csv.tgz\n",
    "#df = pd.read_csv(\"amazon_review_polarity_csv/train.csv\", names=[\"Label\", \"Title\", \"Review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"amazon_review_polarity_csv/test.csv\", names=[\"Label\", \"Title\", \"Review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    200000\n",
       "1    200000\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label      int64\n",
       "Title     object\n",
       "Review    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149518</th>\n",
       "      <td>1</td>\n",
       "      <td>Poor Gilbert :-(</td>\n",
       "      <td>Poor Gilbert! He must have turned over in his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90156</th>\n",
       "      <td>1</td>\n",
       "      <td>too much of bad things can't be good</td>\n",
       "      <td>Usually I am able to fly through books by Larr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32609</th>\n",
       "      <td>2</td>\n",
       "      <td>This is one nice cd.</td>\n",
       "      <td>Nas has done it again. This cd is all that. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175748</th>\n",
       "      <td>1</td>\n",
       "      <td>dont buy</td>\n",
       "      <td>This is trash I dont know who rates this devic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221435</th>\n",
       "      <td>1</td>\n",
       "      <td>Not for technical use.</td>\n",
       "      <td>If you want read guitar amp appreciation, this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316393</th>\n",
       "      <td>2</td>\n",
       "      <td>Written from the heart...</td>\n",
       "      <td>Mr. Sapoznik not only does an enviable job of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175026</th>\n",
       "      <td>1</td>\n",
       "      <td>Functional but not made to withstand travel</td>\n",
       "      <td>Its silly that this bag is so flimsy and not m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309768</th>\n",
       "      <td>1</td>\n",
       "      <td>One of the worst....</td>\n",
       "      <td>I like her aerobics classes on TV but this boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71884</th>\n",
       "      <td>2</td>\n",
       "      <td>The Beasties have done it again!</td>\n",
       "      <td>Wow, what a good CD! I really like the Beastie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143618</th>\n",
       "      <td>1</td>\n",
       "      <td>Sorry I bought it -- a one-time read at most</td>\n",
       "      <td>I saw several good reviews of this book but I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Label                                         Title  \\\n",
       "149518      1                              Poor Gilbert :-(   \n",
       "90156       1          too much of bad things can't be good   \n",
       "32609       2                          This is one nice cd.   \n",
       "175748      1                                      dont buy   \n",
       "221435      1                        Not for technical use.   \n",
       "316393      2                     Written from the heart...   \n",
       "175026      1   Functional but not made to withstand travel   \n",
       "309768      1                          One of the worst....   \n",
       "71884       2              The Beasties have done it again!   \n",
       "143618      1  Sorry I bought it -- a one-time read at most   \n",
       "\n",
       "                                                   Review  \n",
       "149518  Poor Gilbert! He must have turned over in his ...  \n",
       "90156   Usually I am able to fly through books by Larr...  \n",
       "32609   Nas has done it again. This cd is all that. It...  \n",
       "175748  This is trash I dont know who rates this devic...  \n",
       "221435  If you want read guitar amp appreciation, this...  \n",
       "316393  Mr. Sapoznik not only does an enviable job of ...  \n",
       "175026  Its silly that this bag is so flimsy and not m...  \n",
       "309768  I like her aerobics classes on TV but this boo...  \n",
       "71884   Wow, what a good CD! I really like the Beastie...  \n",
       "143618  I saw several good reviews of this book but I ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import csv\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_label = {'1': 'Negative', '2': 'Positive'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_instance(row):\n",
    "    cur_row = []\n",
    "    label = \"__label__\" + index_to_label[row[0]]  #Prefix the index-ed label with __label__\n",
    "    cur_row.append(label)\n",
    "    cur_row.extend(nltk.word_tokenize(row[1].lower()))\n",
    "    cur_row.extend(nltk.word_tokenize(row[2].lower()))\n",
    "    return cur_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_file, output_file, keep=1):\n",
    "    all_rows = []\n",
    "    with open(input_file, 'r') as csvinfile:\n",
    "        csv_reader = csv.reader(csvinfile, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            all_rows.append(row)\n",
    "    shuffle(all_rows)\n",
    "    all_rows = all_rows[:int(keep*len(all_rows))]\n",
    "    pool = Pool(processes=multiprocessing.cpu_count())\n",
    "    transformed_rows = pool.map(transform_instance, all_rows)\n",
    "    pool.close() \n",
    "    pool.join()\n",
    "    \n",
    "    with open(output_file, 'w') as csvoutfile:\n",
    "        csv_writer = csv.writer(csvoutfile, delimiter=' ', lineterminator='\\n')\n",
    "        csv_writer.writerows(transformed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 27s ± 1.88 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Preparing the training dataset\n",
    "\n",
    "# Since preprocessing the whole dataset might take a couple of mintutes,\n",
    "# we keep 20% of the training dataset for this demo.\n",
    "# Set keep to 1 if you want to use the complete dataset\n",
    "preprocess('amazon_review_polarity_csv/train.csv', 'polarity.train', keep=.2)\n",
    "        \n",
    "# Preparing the validation dataset        \n",
    "preprocess('amazon_review_polarity_csv/test.csv', 'polarity.validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.56 s, sys: 1.25 s, total: 5.81 s\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "\n",
    "sess.upload_data(path='polarity.train', bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path='polarity.validation', bucket=bucket, key_prefix=validation_channel)\n",
    "\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SageMaker BlazingText container: 811284229777.dkr.ecr.us-east-1.amazonaws.com/blazingtext:latest (us-east-1)\n"
     ]
    }
   ],
   "source": [
    "region_name = boto3.Session().region_name\n",
    "container = sagemaker.amazon.amazon_estimator.get_image_uri(region_name, \"blazingtext\", \"latest\")\n",
    "print('Using SageMaker BlazingText container: {} ({})'.format(container, region_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_model = sagemaker.estimator.Estimator(container,\n",
    "                                         role, \n",
    "                                         base_job_name = 'qanv',\n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.c4.4xlarge',\n",
    "                                         train_volume_size = 30,\n",
    "                                         train_max_run = 360000,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)\n",
    "bt_model.set_hyperparameters(mode=\"supervised\",\n",
    "                            epochs=10,\n",
    "                            min_count=2,\n",
    "                            learning_rate=0.05,\n",
    "                            vector_dim=10,\n",
    "                            early_stopping=True,\n",
    "                            patience=4,\n",
    "                            min_epochs=5,\n",
    "                            word_ngrams=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='text/plain', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='text/plain', s3_data_type='S3Prefix')\n",
    "data_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: qanv-2019-03-13-15-30-42-360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-13 15:30:42 Starting - Starting the training job...\n",
      "2019-03-13 15:30:44 Starting - Launching requested ML instances......\n",
      "2019-03-13 15:31:51 Starting - Preparing the instances for training......\n",
      "2019-03-13 15:32:59 Downloading - Downloading input data\n",
      "2019-03-13 15:32:59 Training - Training image download completed. Training in progress.\n",
      "\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[03/13/2019 15:32:59 WARNING 139623346853696] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[03/13/2019 15:32:59 WARNING 139623346853696] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[03/13/2019 15:32:59 INFO 139623346853696] nvidia-smi took: 0.0252201557159 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[03/13/2019 15:32:59 INFO 139623346853696] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[31m[03/13/2019 15:32:59 INFO 139623346853696] Processing /opt/ml/input/data/train/polarity.train . File size: 316 MB\u001b[0m\n",
      "\u001b[31m[03/13/2019 15:32:59 INFO 139623346853696] Processing /opt/ml/input/data/validation/polarity.validation . File size: 176 MB\u001b[0m\n",
      "\u001b[31mRead 10M words\u001b[0m\n",
      "\u001b[31mRead 20M words\u001b[0m\n",
      "\u001b[31mRead 30M words\u001b[0m\n",
      "\u001b[31mRead 40M words\u001b[0m\n",
      "\u001b[31mRead 50M words\u001b[0m\n",
      "\u001b[31mRead 60M words\u001b[0m\n",
      "\u001b[31mRead 66M words\u001b[0m\n",
      "\u001b[31mNumber of words:  221784\u001b[0m\n",
      "\u001b[31mLoading validation data from /opt/ml/input/data/validation/polarity.validation\u001b[0m\n",
      "\u001b[31mLoaded validation data.\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 5\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.931882\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0239  Progress: 52.15%  Million Words/sec: 37.77 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0211  Progress: 57.77%  Million Words/sec: 38.08 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 6\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.932048\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0186  Progress: 62.84%  Million Words/sec: 36.96 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0160  Progress: 67.92%  Million Words/sec: 37.30 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 7\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.932685\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0135  Progress: 72.97%  Million Words/sec: 36.41 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0110  Progress: 78.05%  Million Words/sec: 36.72 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 8\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.932007\u001b[0m\n",
      "\u001b[31mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0082  Progress: 83.65%  Million Words/sec: 36.04 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0057  Progress: 88.67%  Million Words/sec: 36.31 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 9\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.933535\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0031  Progress: 93.80%  Million Words/sec: 35.70 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0006  Progress: 98.81%  Million Words/sec: 35.95 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 10\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.93378\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 35.36 #####\u001b[0m\n",
      "\n",
      "2019-03-13 15:33:40 Uploading - Uploading generated training model\u001b[31mTraining finished.\u001b[0m\n",
      "\u001b[31mAverage throughput in Million words/sec: 35.36\u001b[0m\n",
      "\u001b[31mTotal training time in seconds: 18.73\n",
      "\u001b[0m\n",
      "\u001b[31m#train_accuracy: 0.9826\u001b[0m\n",
      "\u001b[31mNumber of train examples: 720000\n",
      "\u001b[0m\n",
      "\u001b[31m#validation_accuracy: 0.9338\u001b[0m\n",
      "\u001b[31mNumber of validation examples: 400000\u001b[0m\n",
      "\n",
      "2019-03-13 15:33:58 Completed - Training job completed\n",
      "Billable seconds: 75\n"
     ]
    }
   ],
   "source": [
    "bt_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: blazingtext-2019-03-13-15-36-04-081\n",
      "INFO:sagemaker:Creating endpoint with name qanv-2019-03-13-15-30-42-360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "text_classifier = bt_model.deploy(initial_instance_count = 1,instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.9999558925628662\n",
      "    ],\n",
      "    \"label\": [\n",
      "      \"__label__Positive\"\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"this python book is easy to use and it has number of useful examples.\"]\n",
    "#sentences = [\"this book is very bad and full of erros.\"]\n",
    "\n",
    "# using the same nltk tokenizer that we used during data preparation for training\n",
    "tokenized_sentences = [' '.join(nltk.word_tokenize(sent)) for sent in sentences]\n",
    "\n",
    "payload = {\"instances\" : tokenized_sentences}\n",
    "\n",
    "response = text_classifier.predict(json.dumps(payload))\n",
    "\n",
    "predictions = json.loads(response)\n",
    "print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.delete_endpoint(text_classifier.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
